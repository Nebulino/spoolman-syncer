import os
import sys
import subprocess
import json
import shutil
import platform
import argparse
import glob
import urllib.request
import urllib.error
import zipfile
import re
import hashlib  # <--- Added for smart dependency checking

# --- Configuration ---
DEFAULT_IP = "localhost"
DEFAULT_PORT = "7912"

# Repo Info
REPO_URL = "https://github.com/bofh69/spoolman2slicer/archive/refs/heads/main.zip"
TOOL_DIR = "spoolman2slicer_tool"  # Folder where we extract the tool
VENV_DIR = ".venv"                 # Hidden venv folder
OUTPUT_DIR = "spools"              # Subfolder for generated configs
NEW_COMMENT = "Generated by Spoolman Syncer (wrapper for spoolman2slicer) and edited for Orca/Bambu"

MATERIAL_MAP = {
    "PLA": "Generic PLA",
    "PETG": "Generic PETG",
    "ABS": "Generic ABS",
    "ASA": "Generic ASA",
    "TPU": "Generic TPU",
    "PC": "Generic PC",
    "PA": "Generic PA",
    "NYLON": "Generic PA",
    "PVA": "Generic PVA",
    "HIPS": "Generic HIPS",
}

def get_venv_python():
    """Returns the path to the python executable inside the venv."""
    if platform.system() == "Windows":
        return os.path.join(VENV_DIR, "Scripts", "python.exe")
    else:
        return os.path.join(VENV_DIR, "bin", "python")

def ensure_dependencies_updated():
    """
    Checks if requirements.txt has changed since last install.
    If changed (or never installed), runs pip install.
    """
    req_file = os.path.join(TOOL_DIR, "requirements.txt")
    hash_file = os.path.join(TOOL_DIR, ".installed_hash")

    if not os.path.exists(req_file):
        return # No requirements to install

    # 1. Calculate current hash of requirements.txt
    with open(req_file, 'rb') as f:
        current_hash = hashlib.md5(f.read()).hexdigest()

    # 2. Read stored hash (if it exists)
    stored_hash = ""
    if os.path.exists(hash_file):
        with open(hash_file, 'r') as f:
            stored_hash = f.read().strip()

    # 3. Compare and Install if needed
    if current_hash != stored_hash:
        print("üì¶ Dependencies changed or missing. Installing/Updating...")
        venv_python = get_venv_python()
        try:
            # Install requirements
            subprocess.check_call([venv_python, "-m", "pip", "install", "-r", req_file])

            # Save new hash so we don't run this next time
            with open(hash_file, 'w') as f:
                f.write(current_hash)
            print("‚úÖ Dependencies updated.")
        except Exception as e:
            print(f"‚ùå Failed to install dependencies: {e}")
            sys.exit(1)
    else:
        # Debug print (optional, mostly silent)
        # print("‚úÖ Dependencies are up to date.")
        pass

def check_and_setup_tool():
    """
    Checks if the tool directory AND the venv exist.
    If not, asks to download/install them.
    Always ensures dependencies are up to date.
    """
    print("üîé Checking for generator module and venv...")

    tool_exists = os.path.exists(TOOL_DIR) and os.path.isdir(TOOL_DIR)
    venv_exists = os.path.exists(VENV_DIR) and os.path.isdir(VENV_DIR)

    if not tool_exists or not venv_exists:
        if not tool_exists:
            print(f"‚ö†Ô∏è  Tool folder '{TOOL_DIR}' is missing.")
        if not venv_exists:
            print(f"‚ö†Ô∏è  Virtual environment '{VENV_DIR}' is missing.")

        try:
            choice = input(f"   Would you like to setup them now? [Y/n]: ").strip().lower()
        except KeyboardInterrupt:
            print("\n‚ùå Operation cancelled.")
            sys.exit(1)

        if choice in ["", "y", "yes"]:
            setup_tool(tool_exists, venv_exists)
        else:
            print("‚ùå Cannot proceed without setup. Exiting.")
            sys.exit(1)
    else:
        print(f"‚úÖ Found local tool in: {TOOL_DIR}")
        print(f"‚úÖ Found virtual environment in: {VENV_DIR}")

    # AFTER checking/installing folders, ALWAYS check if requirements need update
    ensure_dependencies_updated()

def setup_tool(tool_exists, venv_exists):
    """Downloads ZIP, extracts it, and creates venv."""

    # 1. Download & Extract Tool (if missing)
    if not tool_exists:
        zip_name = "repo.zip"
        print(f"‚¨áÔ∏è  Downloading from GitHub ({REPO_URL})...")
        try:
            urllib.request.urlretrieve(REPO_URL, zip_name)

            print("üì¶ Extracting...")
            with zipfile.ZipFile(zip_name, 'r') as zip_ref:
                zip_ref.extractall("temp_extract")

            extracted_root = os.path.join("temp_extract", os.listdir("temp_extract")[0])

            if os.path.exists(TOOL_DIR):
                shutil.rmtree(TOOL_DIR)
            shutil.move(extracted_root, TOOL_DIR)

            os.remove(zip_name)
            shutil.rmtree("temp_extract")
            print(f"‚úÖ Extracted to {TOOL_DIR}")
        except Exception as e:
            print(f"‚ùå Download/Extract Failed: {e}")
            sys.exit(1)

    # 2. Create Venv (if missing)
    if not venv_exists:
        print(f"üî® Creating virtual environment in '{VENV_DIR}'...")
        try:
            subprocess.check_call([sys.executable, "-m", "venv", VENV_DIR])
            print("‚úÖ Venv created.")
        except Exception as e:
            print(f"‚ùå Failed to create venv: {e}")
            sys.exit(1)

    # Note: We removed the direct pip install from here because
    # check_and_setup_tool() now calls ensure_dependencies_updated()
    # immediately after this function finishes.

def construct_and_validate_url(ip, port):
    """Builds URL and validates connectivity."""
    target_host = ip.strip() if ip else "localhost"

    if not target_host.startswith("http"):
        target_host = f"http://{target_host}"

    if ":" not in target_host.split("/")[-1]:
        target_host = f"{target_host}:{port}"

    print(f"üîé Validating connection to Spoolman ({target_host})...")

    try:
        with urllib.request.urlopen(target_host, timeout=3) as response:
            if response.status != 200:
                print(f"‚ö†Ô∏è Server responded with status code: {response.status}")
    except Exception as e:
        print(f"‚ùå Connection Failed: Could not reach Spoolman at {target_host}")
        sys.exit(1)

    print("‚úÖ Connection successful.")
    return target_host

def get_slicer_path(slicer_name):
    """Returns the user directory path for the given slicer."""
    home = os.path.expanduser("~")
    system = platform.system()

    if slicer_name.lower() in ["orca", "orcaslicer"]:
        app_name = "OrcaSlicer"
    elif slicer_name.lower() in ["bambu", "bambustudio", "bambulab"]:
        app_name = "BambuStudio"
    else:
        return None

    if system == "Darwin":  # macOS
        return os.path.join(home, "Library", "Application Support", app_name, "user", "default", "filament")
    elif system == "Windows":
        return os.path.join(os.getenv('APPDATA'), app_name, "user", "default", "filament")
    elif system == "Linux":
        return os.path.join(home, ".config", app_name, "user", "default", "filament")
    return None

def run_spoolman_generator(valid_url):
    """Executes the module using the VENV python, outputting to OUTPUT_DIR."""
    print(f"üöÄ Executing module from {TOOL_DIR}...")

    if not os.path.exists(OUTPUT_DIR):
        os.makedirs(OUTPUT_DIR)
        print(f"üìÅ Created output directory: {OUTPUT_DIR}")

    venv_python = get_venv_python()

    # Command: venv/bin/python -m spoolman2slicer -d spools ...
    cmd = [
        venv_python, "-m", "spoolman2slicer",
        "-s", "orcaslicer",
        "-d", os.path.abspath(OUTPUT_DIR),
        "-u", valid_url
    ]

    env = os.environ.copy()
    env["PYTHONPATH"] = os.path.abspath(TOOL_DIR) + os.pathsep + env.get("PYTHONPATH", "")

    try:
        subprocess.run(cmd, env=env, check=True)
        print("‚úÖ Generation complete.")
    except subprocess.CalledProcessError as e:
        print(f"‚ùå Error executing module: {e}")
        sys.exit(1)

def fix_json_files():
    """Applies compatibility fixes and appends M555 GCODE."""
    print(f"üîß Fixing JSON files in '{OUTPUT_DIR}'...")
    count = 0

    search_path = os.path.join(OUTPUT_DIR, "*.json")

    for filename in glob.glob(search_path):
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                data = json.load(f)

            # --- 1. Smart Inheritance Logic ---
            original_inherits = data.get("inherits", "").upper()
            filament_type = ""
            if "filament_type" in data and len(data["filament_type"]) > 0:
                filament_type = data["filament_type"][0].upper()

            new_inherits = "Generic PLA" # Fallback

            found = False
            for key, value in MATERIAL_MAP.items():
                if key in original_inherits or key in filament_type:
                    new_inherits = value
                    found = True
                    break

            if not found and "inherits" in data:
                new_inherits = data["inherits"]

            # --- 2. Extract Spool ID ---
            spool_id = None
            original_gcode_str = ""

            if "filament_start_gcode" in data and len(data["filament_start_gcode"]) > 0:
                original_gcode_str = data["filament_start_gcode"][0]

            if "filament_settings_id" in data and len(data["filament_settings_id"]) > 0:
                spool_id = data["filament_settings_id"][0]

            if not spool_id and original_gcode_str:
                match = re.search(r"ID=(\d+)", original_gcode_str)
                if match:
                    spool_id = match.group(1)

            # --- 3. Rebuild Data Structure ---
            new_data = {}
            new_data["_comment"] = NEW_COMMENT
            new_data["compatible_printers"] = []
            new_data["compatible_printers_condition"] = ""
            new_data["inherits"] = new_inherits

            skip_keys = ["_comment", "compatible_printers", "compatible_printers_condition", "inherits", "filament_start_gcode"]
            for key, value in data.items():
                if key not in skip_keys:
                    new_data[key] = value

            # --- 4. Append Custom M555 GCODE ---
            if spool_id:
                new_cmd = f"; filament start gcode\nM555 S={spool_id}"

                if original_gcode_str:
                    combined_gcode = f"{original_gcode_str}\n{new_cmd}"
                    new_data["filament_start_gcode"] = [combined_gcode]
                else:
                    new_data["filament_start_gcode"] = [new_cmd]
            else:
                if "filament_start_gcode" in data:
                    new_data["filament_start_gcode"] = data["filament_start_gcode"]

            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(new_data, f, indent=4)
            count += 1
        except Exception as e:
            print(f"‚ö†Ô∏è Failed to fix {filename}: {e}")
    print(f"‚úÖ Fixed {count} JSON files.")

def deploy_files(target_slicer, wipe_destination=False):
    """Copies files to the slicer folder."""
    dest_path = get_slicer_path(target_slicer)
    if not dest_path:
        print("‚ùå Unknown slicer.")
        return

    if not os.path.exists(dest_path):
        print(f"‚ö†Ô∏è Target folder does not exist: {dest_path}")
        return

    if wipe_destination:
        print(f"üßπ Wiping existing JSON profiles in {target_slicer} folder...")
        existing_files = glob.glob(os.path.join(dest_path, "*.json"))
        for f in existing_files:
            try:
                os.remove(f)
            except Exception as e:
                print(f"‚ö†Ô∏è Failed to delete {f}: {e}")

    print(f"üì¶ Deploying to {target_slicer}...")
    count = 0

    search_path = os.path.join(OUTPUT_DIR, "*.json")
    for filename in glob.glob(search_path):
        base_name = os.path.basename(filename)
        shutil.copy(filename, os.path.join(dest_path, base_name))
        count += 1
    print(f"üéâ Success! Copied {count} profiles.")

# --- Main Execution ---
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Spoolman Syncer")
    parser.add_argument("--ip", type=str, default=DEFAULT_IP, help="IP address of Spoolman")
    parser.add_argument("--port", type=str, default=DEFAULT_PORT, help="Port of Spoolman")
    parser.add_argument("--apply", choices=["orcaslicer", "bambulab", "orca", "bambu"], help="Install files")
    parser.add_argument("--delete-first", action="store_true", help="Delete existing JSON files in slicer folder before copying")

    args = parser.parse_args()

    # 1. Setup Module & Venv (and check/update dependencies)
    check_and_setup_tool()

    # 2. Check Network
    final_url = construct_and_validate_url(args.ip, args.port)

    # 3. Generate & Fix (Using Venv)
    run_spoolman_generator(final_url)
    fix_json_files()

    # 4. Install (if requested)
    if args.apply:
        slicer_map = {"orca": "orcaslicer", "orcaslicer": "orcaslicer", "bambu": "bambustudio", "bambulab": "bambustudio"}
        deploy_files(slicer_map[args.apply], wipe_destination=args.delete_first)
    else:
        print("‚ÑπÔ∏è  Run with --apply [orca|bambu] to install automatically.")