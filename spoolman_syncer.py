"""
Spoolman Syncer
----------------
An advanced automation wrapper for the 'spoolman2slicer' utility.

This script acts as a bridge between Spoolman and OrcaSlicer/BambuStudio.
It handles the entire lifecycle:
1. Environment Setup: Auto-downloads the tool and creates an isolated Python venv.
2. Execution: Runs the generator and automatically handles filesystem errors.
3. Post-Processing: Sanitizes filenames, fixes JSON inheritance, and injects Klipper G-code.
4. Deployment: Installs the profiles directly to Slicer user directories.

Author: Nebulino
License: MIT
"""

import os
import sys
import subprocess
import json
import shutil
import platform
import argparse
import glob
import urllib.request
import urllib.error
import zipfile
import re
import hashlib

# --- Configuration Constants ---
DEFAULT_IP = "localhost"
DEFAULT_PORT = "7912"

# Repository and Directory Configuration
REPO_URL = "https://github.com/bofh69/spoolman2slicer/archive/refs/heads/main.zip"
TOOL_DIR = "spoolman2slicer_tool"  # Directory for the external generator tool
VENV_DIR = ".venv"                 # Directory for the isolated virtual environment
OUTPUT_DIR = "spools"              # Directory for generated JSON configurations
NEW_COMMENT = "Generated by Spoolman Syncer and edited for Orca/Bambu"

# Material mapping for standardizing "Inherits" fields in Slicers
MATERIAL_MAP = {
    "PLA": "Generic PLA",
    "PETG": "Generic PETG",
    "ABS": "Generic ABS",
    "ASA": "Generic ASA",
    "TPU": "Generic TPU",
    "PC": "Generic PC",
    "PA": "Generic PA",
    "NYLON": "Generic PA",
    "PVA": "Generic PVA",
    "HIPS": "Generic HIPS",
}

def get_venv_python():
    """
    Determines the correct path to the Python executable within the virtual environment.
    """
    if platform.system() == "Windows":
        return os.path.join(VENV_DIR, "Scripts", "python.exe")
    else:
        return os.path.join(VENV_DIR, "bin", "python")

def clean_environment(level="all"):
    """
    Cleans up directories based on the specified level.
    Args:
        level (str): 'all' (tool, venv, spools) or 'spool' (only spools).
    """
    if level == "spool":
        print(f"üßπ Cleaning output directory: {OUTPUT_DIR}...")
        if os.path.exists(OUTPUT_DIR):
            try:
                shutil.rmtree(OUTPUT_DIR)
                print("   ‚úÖ Deleted 'spools' directory.")
            except Exception as e:
                print(f"   ‚ùå Failed to delete spools: {e}")

    elif level == "all":
        print("üßπ Performing full cleanup (Factory Reset)...")
        targets = [TOOL_DIR, VENV_DIR, OUTPUT_DIR]
        for target in targets:
            if os.path.exists(target):
                try:
                    shutil.rmtree(target)
                    print(f"   ‚úÖ Deleted '{target}'")
                except Exception as e:
                    print(f"   ‚ùå Failed to delete '{target}': {e}")
        print("‚ú® Cleanup complete. Run the script again to re-initialize.")
        sys.exit(0)

def ensure_dependencies_updated():
    """
    Verifies the integrity of installed dependencies by hashing requirements.txt.
    """
    req_file = os.path.join(TOOL_DIR, "requirements.txt")
    hash_file = os.path.join(TOOL_DIR, ".installed_hash")

    if not os.path.exists(req_file):
        return

        # Calculate current hash
    with open(req_file, 'rb') as f:
        current_hash = hashlib.md5(f.read()).hexdigest()

    # Read stored hash
    stored_hash = ""
    if os.path.exists(hash_file):
        with open(hash_file, 'r') as f:
            stored_hash = f.read().strip()

    # Compare and Update
    if current_hash != stored_hash:
        print("üì¶ Dependencies changed or missing. Updating environment...")
        venv_python = get_venv_python()
        try:
            subprocess.check_call([venv_python, "-m", "pip", "install", "-r", req_file])
            with open(hash_file, 'w') as f:
                f.write(current_hash)
            print("‚úÖ Dependencies updated successfully.")
        except subprocess.CalledProcessError:
            print("‚ùå Failed to install dependencies.")
            sys.exit(1)

def check_and_setup_tool():
    """
    Checks for the existence of the generator tool and virtual environment.
    """
    print("üîé Verifying environment integrity...")

    tool_exists = os.path.exists(TOOL_DIR) and os.path.isdir(TOOL_DIR)
    venv_exists = os.path.exists(VENV_DIR) and os.path.isdir(VENV_DIR)

    if not tool_exists or not venv_exists:
        if not tool_exists:
            print(f"‚ö†Ô∏è  Generator tool '{TOOL_DIR}' is missing.")
        if not venv_exists:
            print(f"‚ö†Ô∏è  Virtual environment '{VENV_DIR}' is missing.")

        try:
            choice = input(f"   Initialize setup now? [Y/n]: ").strip().lower()
        except KeyboardInterrupt:
            print("\n‚ùå Operation cancelled.")
            sys.exit(1)

        if choice in ["", "y", "yes"]:
            setup_tool(tool_exists, venv_exists)
        else:
            print("‚ùå Setup required to proceed. Exiting.")
            sys.exit(1)
    else:
        print(f"‚úÖ Environment verified.")

    ensure_dependencies_updated()

def setup_tool(tool_exists, venv_exists):
    """
    Downloads the upstream repository and creates a python virtual environment.
    """
    if not tool_exists:
        zip_name = "repo.zip"
        print(f"‚¨áÔ∏è  Downloading upstream repository ({REPO_URL})...")
        try:
            urllib.request.urlretrieve(REPO_URL, zip_name)

            print("üì¶ Extracting archive...")
            with zipfile.ZipFile(zip_name, 'r') as zip_ref:
                zip_ref.extractall("temp_extract")

            extracted_root = os.path.join("temp_extract", os.listdir("temp_extract")[0])

            if os.path.exists(TOOL_DIR):
                shutil.rmtree(TOOL_DIR)
            shutil.move(extracted_root, TOOL_DIR)

            os.remove(zip_name)
            shutil.rmtree("temp_extract")
            print(f"‚úÖ Installed tool to: {TOOL_DIR}")
        except Exception as e:
            print(f"‚ùå Setup failed: {e}")
            sys.exit(1)

    if not venv_exists:
        print(f"üî® Creating virtual environment in '{VENV_DIR}'...")
        try:
            subprocess.check_call([sys.executable, "-m", "venv", VENV_DIR])
            print("‚úÖ Virtual environment created.")
        except Exception as e:
            print(f"‚ùå Failed to create venv: {e}")
            sys.exit(1)

def construct_and_validate_url(ip, port):
    """
    Constructs the Spoolman API URL and validates network connectivity.
    """
    target_host = ip.strip() if ip else "localhost"

    if not target_host.startswith("http"):
        target_host = f"http://{target_host}"

    if ":" not in target_host.split("/")[-1]:
        target_host = f"{target_host}:{port}"

    print(f"üîé Connecting to Spoolman at {target_host}...")

    try:
        with urllib.request.urlopen(target_host, timeout=3) as response:
            if response.status != 200:
                print(f"‚ö†Ô∏è Server responded with status code: {response.status}")
    except Exception as e:
        print(f"‚ùå Connection Failed: Could not reach Spoolman at {target_host}")
        print("   Please check your IP/Port and ensure Spoolman is running.")
        sys.exit(1)

    print("‚úÖ Connection confirmed.")
    return target_host

def get_slicer_base_path(slicer_name):
    """
    Returns the ROOT 'user' directory for the given slicer.
    Example: .../OrcaSlicer/user/
    """
    home = os.path.expanduser("~")
    system = platform.system()

    if slicer_name.lower() in ["orca", "orcaslicer"]:
        app_name = "OrcaSlicer"
    elif slicer_name.lower() in ["bambu", "bambustudio", "bambulab"]:
        app_name = "BambuStudio"
    else:
        return None

    if system == "Darwin":  # macOS
        return os.path.join(home, "Library", "Application Support", app_name, "user")
    elif system == "Windows":
        return os.path.join(os.getenv('APPDATA'), app_name, "user")
    elif system == "Linux":
        return os.path.join(home, ".config", app_name, "user")
    return None

def run_spoolman_generator(valid_url):
    """
    Runs the spoolman2slicer module inside the virtual environment.
    Catches and handles directory errors caused by complex filenames.
    """
    print(f"üöÄ Generating profiles...")

    if not os.path.exists(OUTPUT_DIR):
        os.makedirs(OUTPUT_DIR)

    venv_python = get_venv_python()
    if not os.path.exists(venv_python):
        print(f"‚ùå Python executable not found in venv: {venv_python}")
        print("   Try running with --clean to reset the environment.")
        sys.exit(1)

    cmd = [
        venv_python, "-m", "spoolman2slicer",
        "-s", "orcaslicer",
        "-d", os.path.abspath(OUTPUT_DIR),
        "-u", valid_url
    ]

    env = os.environ.copy()
    env["PYTHONPATH"] = os.path.abspath(TOOL_DIR) + os.pathsep + env.get("PYTHONPATH", "")

    max_retries = 10
    attempts = 0

    while attempts < max_retries:
        try:
            subprocess.run(cmd, env=env, check=True, capture_output=True, text=True)
            print("‚úÖ Generation complete.")
            break
        except subprocess.CalledProcessError as e:
            err_msg = e.stderr or ""

            # Handle "No such file" due to slashes in names
            if "No such file or directory" in err_msg:
                match = re.search(r"No such file or directory: '(.+?)'", err_msg)
                if match:
                    missing_file_path = match.group(1)
                    missing_dir = os.path.dirname(missing_file_path)

                    if not os.path.exists(missing_dir):
                        print(f"‚ö†Ô∏è  Tool blocked by complex path. Auto-creating directory: {os.path.basename(missing_dir)}")
                        os.makedirs(missing_dir, exist_ok=True)
                        attempts += 1
                        continue

            print(f"‚ùå Generator module crashed.")
            print(f"   Error log: {err_msg.strip()}")
            sys.exit(1)

def sanitize_and_flatten_filenames():
    """
    Moves files from generated subdirectories back to root and sanitizes names.
    """
    print(f"üßπ Sanitizing and flattening filenames in '{OUTPUT_DIR}'...")
    count = 0

    # Recursive search for all json files
    search_path = os.path.join(OUTPUT_DIR, "**", "*.json")

    for file_path in glob.glob(search_path, recursive=True):
        if os.path.dirname(file_path) == os.path.abspath(OUTPUT_DIR):
            continue

        rel_path = os.path.relpath(file_path, OUTPUT_DIR)
        safe_name = rel_path.replace(os.sep, " - ")
        safe_name = safe_name.replace(" -  - ", " - ")

        replacements = {":": "-", "*": "", "?": "", "\"": "", "<": "", ">": "", "|": ""}
        for char, rep in replacements.items():
            safe_name = safe_name.replace(char, rep)

        new_full_path = os.path.join(OUTPUT_DIR, safe_name)

        try:
            shutil.move(file_path, new_full_path)
            count += 1
        except Exception as e:
            print(f"   ‚ùå Failed to move '{rel_path}': {e}")

    # Cleanup empty directories
    for root, dirs, files in os.walk(OUTPUT_DIR, topdown=False):
        for name in dirs:
            dir_path = os.path.join(root, name)
            try:
                os.rmdir(dir_path)
            except:
                pass

    if count > 0:
        print(f"‚úÖ Flattened and renamed {count} nested files.")
    else:
        print("‚úÖ No nested files found.")

def fix_json_files():
    """
    Iterates through generated JSON files to Fix inheritance and Inject G-Code.
    """
    print(f"üîß Post-processing JSON files...")
    count = 0
    search_path = os.path.join(OUTPUT_DIR, "*.json")

    for filename in glob.glob(search_path):
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                data = json.load(f)

            # Smart Inheritance
            original_inherits = data.get("inherits", "").upper()
            filament_type = ""
            if "filament_type" in data and len(data["filament_type"]) > 0:
                filament_type = data["filament_type"][0].upper()

            new_inherits = "Generic PLA" # Fallback
            found = False
            for key, value in MATERIAL_MAP.items():
                if key in original_inherits or key in filament_type:
                    new_inherits = value
                    found = True
                    break

            if not found and "inherits" in data:
                new_inherits = data["inherits"]

            # Spool ID Extraction
            spool_id = None
            original_gcode_str = ""

            if "filament_start_gcode" in data and len(data["filament_start_gcode"]) > 0:
                original_gcode_str = data["filament_start_gcode"][0]

            if "filament_settings_id" in data and len(data["filament_settings_id"]) > 0:
                spool_id = data["filament_settings_id"][0]

            # Fallback to regex if ID wasn't in settings
            if not spool_id and original_gcode_str:
                match = re.search(r"ID=(\d+)", original_gcode_str)
                if match:
                    spool_id = match.group(1)

            # Rebuild Data
            new_data = {}
            new_data["_comment"] = NEW_COMMENT
            new_data["compatible_printers"] = []
            new_data["compatible_printers_condition"] = ""
            new_data["inherits"] = new_inherits

            skip_keys = ["_comment", "compatible_printers", "compatible_printers_condition", "inherits", "filament_start_gcode"]
            for key, value in data.items():
                if key not in skip_keys:
                    new_data[key] = value

            # Inject G-Code
            if spool_id:
                new_cmd = f"; filament start gcode\nM555 S={spool_id}"
                new_data["filament_start_gcode"] = [new_cmd]
            else:
                # Keep original if no ID found
                if "filament_start_gcode" in data:
                    new_data["filament_start_gcode"] = data["filament_start_gcode"]

            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(new_data, f, indent=4)
            count += 1
        except Exception as e:
            print(f"‚ö†Ô∏è Error processing {filename}: {e}")

    print(f"‚úÖ Processed {count} profiles.")

def deploy_files(target_slicer, wipe_destination=False, force_all_users=False):
    """
    Deploys the generated files to the target Slicer directory.

    Args:
        target_slicer (str): 'orcaslicer' or 'bambustudio'
        wipe_destination (bool): Delete existing files before copying.
        force_all_users (bool): If True, copy to ALL user folders found.
    """
    base_user_path = get_slicer_base_path(target_slicer)
    if not base_user_path:
        print("‚ùå Error: Unsupported slicer selected.")
        return

    if not os.path.exists(base_user_path):
        print(f"‚ö†Ô∏è Error: Target user directory does not exist: {base_user_path}")
        return

    # Determine which user directories to target
    target_dirs = []

    if force_all_users:
        print(f"üë• Mode enabled: Scanning ALL user directories in {base_user_path}...")
        # List all subdirectories in the user folder
        try:
            subdirs = [d for d in os.listdir(base_user_path) if os.path.isdir(os.path.join(base_user_path, d))]
            target_dirs = subdirs
            if not target_dirs:
                print("   ‚ö†Ô∏è No user directories found.")
        except Exception as e:
            print(f"   ‚ùå Failed to scan directories: {e}")
            return
    else:
        # Default behavior: Only 'default'
        target_dirs = ["default"]

    # Iterate over every targeted user folder
    files_to_copy = glob.glob(os.path.join(OUTPUT_DIR, "*.json"))

    for user_dir in target_dirs:
        dest_filament_path = os.path.join(base_user_path, user_dir, "filament")

        # Ensure the 'filament' folder exists
        if not os.path.exists(dest_filament_path):
            if not force_all_users:
                # If specifically targeting 'default' and it's missing, that's an issue
                print(f"‚ö†Ô∏è Target folder does not exist: {dest_filament_path}")
                continue
            else:
                # In force-all mode, we might need to create it (e.g. for logged in users)
                try:
                    os.makedirs(dest_filament_path, exist_ok=True)
                except Exception:
                    continue

        print(f"üì¶ Deploying to user '{user_dir}'...")

        # Wipe logic
        if wipe_destination:
            print(f"   üßπ Wiping existing profiles...")
            existing_files = glob.glob(os.path.join(dest_filament_path, "*.json"))
            for f in existing_files:
                try:
                    os.remove(f)
                except Exception as e:
                    print(f"   ‚ö†Ô∏è Failed to delete {os.path.basename(f)}: {e}")

        # Copy logic
        count = 0
        for filename in files_to_copy:
            base_name = os.path.basename(filename)
            try:
                shutil.copy(filename, os.path.join(dest_filament_path, base_name))
                count += 1
            except Exception as e:
                print(f"   ‚ùå Failed to copy {base_name}: {e}")

        print(f"   üéâ Copied {count} profiles.")

# --- Main Execution Flow ---
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Spoolman Syncer - Spoolman to Slicer Automation Tool")

    # Connection Args
    parser.add_argument("--ip", type=str, default=DEFAULT_IP, help="Spoolman Server IP (default: localhost)")
    parser.add_argument("--port", type=str, default=DEFAULT_PORT, help="Spoolman Server Port (default: 7912)")

    # Operation Args
    parser.add_argument("--apply", choices=["orcaslicer", "bambulab", "orca", "bambu"], help="Automatically install profiles to the specified slicer")

    # Cleaning & Advanced Args
    parser.add_argument("--delete-first", action="store_true", help="Delete all existing files in the Slicer directory before installing")
    parser.add_argument("--force-all-user", action="store_true", help="Deploy to ALL user directories found (not just 'default')")
    parser.add_argument("--clean-spool", action="store_true", help="Clean local generated 'spools' directory before running")
    parser.add_argument("--clean", action="store_true", help="FACTORY RESET: Delete tool, venv, and spools directories, then exit")

    args = parser.parse_args()

    # 1. Handle Full Cleanup
    if args.clean:
        clean_environment("all")
    if args.clean_spool:
        clean_environment("spool")

    # 2. Setup
    check_and_setup_tool()

    # 3. Connection
    final_url = construct_and_validate_url(args.ip, args.port)

    # 4. Core Logic
    run_spoolman_generator(final_url)
    sanitize_and_flatten_filenames()
    fix_json_files()

    # 5. Install
    if args.apply:
        slicer_map = {
            "orca": "orcaslicer",
            "orcaslicer": "orcaslicer",
            "bambu": "bambustudio",
            "bambulab": "bambustudio"
        }
        deploy_files(
            slicer_map[args.apply],
            wipe_destination=args.delete_first,
            force_all_users=args.force_all_user
        )
    else:
        print("‚ÑπÔ∏è  Files generated in 'spools/'. Run with --apply [orca|bambu] to install automatically.")