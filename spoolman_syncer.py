"""
Spoolman Syncer
----------------
An advanced automation wrapper for the 'spoolman2slicer' utility.

This script acts as a bridge between Spoolman and OrcaSlicer/BambuStudio.
It handles the entire lifecycle:
1. Environment Setup: Auto-downloads the tool and creates an isolated Python venv.
2. Execution: Runs the generator and automatically handles filesystem errors (like 'PLA+/Pro' crashes).
3. Post-Processing: Sanitizes filenames, fixes JSON inheritance, and injects Klipper G-code.
4. Deployment: Installs the profiles directly to the Slicer's user directory.

Author: Nebulino
License: MIT
"""

import os
import sys
import subprocess
import json
import shutil
import platform
import argparse
import glob
import urllib.request
import urllib.error
import zipfile
import re
import hashlib

# --- Configuration Constants ---
DEFAULT_IP = "localhost"
DEFAULT_PORT = "7912"

# Repository and Directory Configuration
REPO_URL = "https://github.com/bofh69/spoolman2slicer/archive/refs/heads/main.zip"
TOOL_DIR = "spoolman2slicer_tool"  # Directory for the external generator tool
VENV_DIR = ".venv"                 # Directory for the isolated virtual environment
OUTPUT_DIR = "spools"              # Directory for generated JSON configurations
NEW_COMMENT = "Generated by Spoolman Syncer and edited for Orca/Bambu"

# Material mapping for standardizing "Inherits" fields in Slicers
# This prevents Slicers from rejecting files with unknown base types.
MATERIAL_MAP = {
    "PLA": "Generic PLA",
    "PETG": "Generic PETG",
    "ABS": "Generic ABS",
    "ASA": "Generic ASA",
    "TPU": "Generic TPU",
    "PC": "Generic PC",
    "PA": "Generic PA",
    "NYLON": "Generic PA",
    "PVA": "Generic PVA",
    "HIPS": "Generic HIPS",
}

def get_venv_python():
    """
    Determines the correct path to the Python executable within the virtual environment.

    Returns:
        str: Absolute path to the python executable.
    """
    if platform.system() == "Windows":
        return os.path.join(VENV_DIR, "Scripts", "python.exe")
    else:
        return os.path.join(VENV_DIR, "bin", "python")

def clean_environment(level="all"):
    """
    Cleans up directories based on the specified level.

    Args:
        level (str): 'all' (tool, venv, spools) or 'spool' (only spools).
    """
    if level == "spool":
        print(f"üßπ Cleaning output directory: {OUTPUT_DIR}...")
        if os.path.exists(OUTPUT_DIR):
            try:
                shutil.rmtree(OUTPUT_DIR)
                print("   ‚úÖ Deleted 'spools' directory.")
            except Exception as e:
                print(f"   ‚ùå Failed to delete spools: {e}")

    elif level == "all":
        print("üßπ Performing full cleanup (Factory Reset)...")
        targets = [TOOL_DIR, VENV_DIR, OUTPUT_DIR]
        for target in targets:
            if os.path.exists(target):
                try:
                    shutil.rmtree(target)
                    print(f"   ‚úÖ Deleted '{target}'")
                except Exception as e:
                    print(f"   ‚ùå Failed to delete '{target}': {e}")
        print("‚ú® Cleanup complete. Run the script again to re-initialize.")
        sys.exit(0)

def ensure_dependencies_updated():
    """
    Verifies the integrity of installed dependencies by hashing requirements.txt.
    If the hash differs from the stored state (e.g. after a tool update),
    it triggers a pip install/update automatically.
    """
    req_file = os.path.join(TOOL_DIR, "requirements.txt")
    hash_file = os.path.join(TOOL_DIR, ".installed_hash")

    if not os.path.exists(req_file):
        return

        # Calculate current hash
    with open(req_file, 'rb') as f:
        current_hash = hashlib.md5(f.read()).hexdigest()

    # Read stored hash
    stored_hash = ""
    if os.path.exists(hash_file):
        with open(hash_file, 'r') as f:
            stored_hash = f.read().strip()

    # Compare and Update
    if current_hash != stored_hash:
        print("üì¶ Dependencies changed or missing. Updating environment...")
        venv_python = get_venv_python()
        try:
            subprocess.check_call([venv_python, "-m", "pip", "install", "-r", req_file])
            with open(hash_file, 'w') as f:
                f.write(current_hash)
            print("‚úÖ Dependencies updated successfully.")
        except subprocess.CalledProcessError:
            print("‚ùå Failed to install dependencies.")
            sys.exit(1)

def check_and_setup_tool():
    """
    Checks for the existence of the generator tool and virtual environment.
    Initiates automatic setup if components are missing.
    """
    print("üîé Verifying environment integrity...")

    tool_exists = os.path.exists(TOOL_DIR) and os.path.isdir(TOOL_DIR)
    venv_exists = os.path.exists(VENV_DIR) and os.path.isdir(VENV_DIR)

    if not tool_exists or not venv_exists:
        if not tool_exists:
            print(f"‚ö†Ô∏è  Generator tool '{TOOL_DIR}' is missing.")
        if not venv_exists:
            print(f"‚ö†Ô∏è  Virtual environment '{VENV_DIR}' is missing.")

        try:
            choice = input(f"   Initialize setup now? [Y/n]: ").strip().lower()
        except KeyboardInterrupt:
            print("\n‚ùå Operation cancelled.")
            sys.exit(1)

        if choice in ["", "y", "yes"]:
            setup_tool(tool_exists, venv_exists)
        else:
            print("‚ùå Setup required to proceed. Exiting.")
            sys.exit(1)
    else:
        print(f"‚úÖ Environment verified.")

    # Always ensure dependencies match the requirements.txt
    ensure_dependencies_updated()

def setup_tool(tool_exists, venv_exists):
    """
    Downloads the upstream repository and creates a python virtual environment.
    """
    # 1. Download & Extract Tool
    if not tool_exists:
        zip_name = "repo.zip"
        print(f"‚¨áÔ∏è  Downloading upstream repository ({REPO_URL})...")
        try:
            urllib.request.urlretrieve(REPO_URL, zip_name)

            print("üì¶ Extracting archive...")
            with zipfile.ZipFile(zip_name, 'r') as zip_ref:
                zip_ref.extractall("temp_extract")

            # Locate the extracted root folder (usually 'spoolman2slicer-main')
            extracted_root = os.path.join("temp_extract", os.listdir("temp_extract")[0])

            if os.path.exists(TOOL_DIR):
                shutil.rmtree(TOOL_DIR)
            shutil.move(extracted_root, TOOL_DIR)

            # Cleanup temp files
            os.remove(zip_name)
            shutil.rmtree("temp_extract")
            print(f"‚úÖ Installed tool to: {TOOL_DIR}")
        except Exception as e:
            print(f"‚ùå Setup failed: {e}")
            sys.exit(1)

    # 2. Create Virtual Environment
    if not venv_exists:
        print(f"üî® Creating virtual environment in '{VENV_DIR}'...")
        try:
            # Use sys.executable to ensure we use the SAME python version that ran this script
            subprocess.check_call([sys.executable, "-m", "venv", VENV_DIR])
            print("‚úÖ Virtual environment created.")
        except Exception as e:
            print(f"‚ùå Failed to create venv: {e}")
            sys.exit(1)

def construct_and_validate_url(ip, port):
    """
    Constructs the Spoolman API URL and validates network connectivity.
    """
    target_host = ip.strip() if ip else "localhost"

    if not target_host.startswith("http"):
        target_host = f"http://{target_host}"

    if ":" not in target_host.split("/")[-1]:
        target_host = f"{target_host}:{port}"

    print(f"üîé Connecting to Spoolman at {target_host}...")

    try:
        with urllib.request.urlopen(target_host, timeout=3) as response:
            if response.status != 200:
                print(f"‚ö†Ô∏è Server responded with status code: {response.status}")
    except Exception as e:
        print(f"‚ùå Connection Failed: Could not reach Spoolman at {target_host}")
        print("   Please check your IP/Port and ensure Spoolman is running.")
        sys.exit(1)

    print("‚úÖ Connection confirmed.")
    return target_host

def get_slicer_path(slicer_name):
    """Resolves the filament configuration directory for the target Slicer OS."""
    home = os.path.expanduser("~")
    system = platform.system()

    if slicer_name.lower() in ["orca", "orcaslicer"]:
        app_name = "OrcaSlicer"
    elif slicer_name.lower() in ["bambu", "bambustudio", "bambulab"]:
        app_name = "BambuStudio"
    else:
        return None

    if system == "Darwin":  # macOS
        return os.path.join(home, "Library", "Application Support", app_name, "user", "default", "filament")
    elif system == "Windows":
        return os.path.join(os.getenv('APPDATA'), app_name, "user", "default", "filament")
    elif system == "Linux":
        return os.path.join(home, ".config", app_name, "user", "default", "filament")
    return None

def run_spoolman_generator(valid_url):
    """
    Runs the spoolman2slicer module inside the virtual environment.

    CRASH HANDLING:
    If the external tool crashes because a filename contains '/' (e.g. 'PLA+/Pro'),
    Python treats it as a directory path that doesn't exist.
    This function catches that specific error, creates the directory on the fly,
    and retries, allowing the tool to finish safely.
    """
    print(f"üöÄ Generating profiles...")

    if not os.path.exists(OUTPUT_DIR):
        os.makedirs(OUTPUT_DIR)

    venv_python = get_venv_python()
    if not os.path.exists(venv_python):
        print(f"‚ùå Python executable not found in venv: {venv_python}")
        print("   Try running with --clean to reset the environment.")
        sys.exit(1)

    cmd = [
        venv_python, "-m", "spoolman2slicer",
        "-s", "orcaslicer",
        "-d", os.path.abspath(OUTPUT_DIR),
        "-u", valid_url
    ]

    env = os.environ.copy()
    env["PYTHONPATH"] = os.path.abspath(TOOL_DIR) + os.pathsep + env.get("PYTHONPATH", "")

    max_retries = 10
    attempts = 0

    while attempts < max_retries:
        try:
            # capture_output=True allows us to read stderr if it crashes
            subprocess.run(cmd, env=env, check=True, capture_output=True, text=True)
            print("‚úÖ Generation complete.")
            break
        except subprocess.CalledProcessError as e:
            err_msg = e.stderr or ""

            # Check for the specific "No such file or directory" error caused by slash in filename
            if "No such file or directory" in err_msg:
                # Extract the path from error: [Errno 2] No such file: '/path/to/spools/PLA+/Pro.json'
                match = re.search(r"No such file or directory: '(.+?)'", err_msg)
                if match:
                    missing_file_path = match.group(1)
                    missing_dir = os.path.dirname(missing_file_path)

                    # If the directory doesn't exist, create it and retry
                    if not os.path.exists(missing_dir):
                        print(f"‚ö†Ô∏è  Tool blocked by complex path. Auto-creating directory: {os.path.basename(missing_dir)}")
                        os.makedirs(missing_dir, exist_ok=True)
                        attempts += 1
                        continue # Retry the loop

            # If it's a different error or we ran out of retries
            print(f"‚ùå Generator module crashed.")
            print(f"   Error log: {err_msg.strip()}")
            sys.exit(1)

def sanitize_and_flatten_filenames():
    """
    Post-crash Cleanup:
    If the generator created subdirectories (e.g., spools/PLA+/Pro.json) to survive the crash,
    this function moves those files back to the root (spools/PLA+ - Pro.json)
    and deletes the empty folders.
    """
    print(f"üßπ Sanitizing and flattening filenames in '{OUTPUT_DIR}'...")
    count = 0

    # Recursive search for all json files
    search_path = os.path.join(OUTPUT_DIR, "**", "*.json")

    for file_path in glob.glob(search_path, recursive=True):
        # Skip files already in the root output dir
        if os.path.dirname(file_path) == os.path.abspath(OUTPUT_DIR):
            continue

            # File is in a subdirectory. Construct new safe name.
        # e.g., "PLA+/Pro.json" -> "PLA+ - Pro.json"
        rel_path = os.path.relpath(file_path, OUTPUT_DIR)

        # Replace OS separator with ' - '
        safe_name = rel_path.replace(os.sep, " - ")

        # Clean up double spaces or weird chars
        safe_name = safe_name.replace(" -  - ", " - ")
        replacements = {":": "-", "*": "", "?": "", "\"": "", "<": "", ">": "", "|": ""}
        for char, rep in replacements.items():
            safe_name = safe_name.replace(char, rep)

        new_full_path = os.path.join(OUTPUT_DIR, safe_name)

        try:
            shutil.move(file_path, new_full_path)
            count += 1
        except Exception as e:
            print(f"   ‚ùå Failed to move '{rel_path}': {e}")

    # Second pass: Cleanup empty directories
    for root, dirs, files in os.walk(OUTPUT_DIR, topdown=False):
        for name in dirs:
            dir_path = os.path.join(root, name)
            try:
                os.rmdir(dir_path) # remove empty dirs
            except:
                pass

    if count > 0:
        print(f"‚úÖ Flattened and renamed {count} nested files.")
    else:
        print("‚úÖ No nested files found.")

def fix_json_files():
    """
    Iterates through generated JSON files to:
    1. Fix inheritance (Material mapping).
    2. Inject custom G-Code for Klipper ID tracking.
    """
    print(f"üîß Post-processing JSON files...")
    count = 0
    search_path = os.path.join(OUTPUT_DIR, "*.json")

    for filename in glob.glob(search_path):
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                data = json.load(f)

            # --- 1. Smart Inheritance Logic ---
            original_inherits = data.get("inherits", "").upper()
            filament_type = ""
            if "filament_type" in data and len(data["filament_type"]) > 0:
                filament_type = data["filament_type"][0].upper()

            new_inherits = "Generic PLA" # Fallback
            found = False
            for key, value in MATERIAL_MAP.items():
                if key in original_inherits or key in filament_type:
                    new_inherits = value
                    found = True
                    break

            if not found and "inherits" in data:
                new_inherits = data["inherits"]

            # --- 2. Extract Spool ID ---
            spool_id = None
            original_gcode_str = ""

            if "filament_start_gcode" in data and len(data["filament_start_gcode"]) > 0:
                original_gcode_str = data["filament_start_gcode"][0]

            if "filament_settings_id" in data and len(data["filament_settings_id"]) > 0:
                spool_id = data["filament_settings_id"][0]

            # Regex fallback
            if not spool_id and original_gcode_str:
                match = re.search(r"ID=(\d+)", original_gcode_str)
                if match:
                    spool_id = match.group(1)

            # --- 3. Rebuild Data ---
            new_data = {}
            new_data["_comment"] = NEW_COMMENT
            new_data["compatible_printers"] = []
            new_data["compatible_printers_condition"] = ""
            new_data["inherits"] = new_inherits

            skip_keys = ["_comment", "compatible_printers", "compatible_printers_condition", "inherits", "filament_start_gcode"]
            for key, value in data.items():
                if key not in skip_keys:
                    new_data[key] = value

            # --- 4. Inject G-Code ---
            if spool_id:
                new_cmd = f"; filament start gcode\nM555 S={spool_id}"

                if original_gcode_str:
                    combined_gcode = f"{original_gcode_str}\n{new_cmd}"
                    new_data["filament_start_gcode"] = [combined_gcode]
                else:
                    new_data["filament_start_gcode"] = [new_cmd]
            else:
                if "filament_start_gcode" in data:
                    new_data["filament_start_gcode"] = data["filament_start_gcode"]

            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(new_data, f, indent=4)
            count += 1
        except Exception as e:
            print(f"‚ö†Ô∏è Error processing {filename}: {e}")

    print(f"‚úÖ Processed {count} profiles.")

def deploy_files(target_slicer, wipe_destination=False):
    """
    Deploys the generated files to the target Slicer directory.
    Optionally wipes the destination folder before copying.
    """
    dest_path = get_slicer_path(target_slicer)
    if not dest_path:
        print("‚ùå Error: Unsupported slicer selected.")
        return

    if not os.path.exists(dest_path):
        print(f"‚ö†Ô∏è Error: Target directory does not exist: {dest_path}")
        return

    if wipe_destination:
        print(f"üßπ Wiping existing profiles in {target_slicer} directory...")
        existing_files = glob.glob(os.path.join(dest_path, "*.json"))
        for f in existing_files:
            try:
                os.remove(f)
            except Exception as e:
                print(f"‚ö†Ô∏è Failed to delete {f}: {e}")

    print(f"üì¶ Deploying to {target_slicer}...")
    count = 0
    search_path = os.path.join(OUTPUT_DIR, "*.json")

    for filename in glob.glob(search_path):
        base_name = os.path.basename(filename)
        shutil.copy(filename, os.path.join(dest_path, base_name))
        count += 1
    print(f"üéâ Success! Deployed {count} profiles.")

# --- Main Execution Flow ---
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Spoolman Syncer - Spoolman to Slicer Automation Tool")

    # Connection Args
    parser.add_argument("--ip", type=str, default=DEFAULT_IP, help="Spoolman Server IP (default: localhost)")
    parser.add_argument("--port", type=str, default=DEFAULT_PORT, help="Spoolman Server Port (default: 7912)")

    # Operation Args
    parser.add_argument("--apply", choices=["orcaslicer", "bambulab", "orca", "bambu"], help="Automatically install profiles to the specified slicer")

    # Cleaning Args
    parser.add_argument("--delete-first", action="store_true", help="Delete all existing files in the Slicer directory before installing")
    parser.add_argument("--clean-spool", action="store_true", help="Clean local generated 'spools' directory before running")
    parser.add_argument("--clean", action="store_true", help="FACTORY RESET: Delete tool, venv, and spools directories, then exit")

    args = parser.parse_args()

    # 1. Handle Full Cleanup
    if args.clean:
        clean_environment("all")
    if args.clean_spool:
        clean_environment("spool")

    # 2. Setup
    check_and_setup_tool()

    # 3. Connection
    final_url = construct_and_validate_url(args.ip, args.port)

    # 4. Core Logic
    # Run generator -> Catch crash -> flatten dirs -> Fix content
    run_spoolman_generator(final_url)
    sanitize_and_flatten_filenames()
    fix_json_files()

    # 5. Install
    if args.apply:
        slicer_map = {
            "orca": "orcaslicer",
            "orcaslicer": "orcaslicer",
            "bambu": "bambustudio",
            "bambulab": "bambustudio"
        }
        deploy_files(slicer_map[args.apply], wipe_destination=args.delete_first)
    else:
        print("‚ÑπÔ∏è  Files generated in 'spools/'. Run with --apply [orca|bambu] to install automatically.")